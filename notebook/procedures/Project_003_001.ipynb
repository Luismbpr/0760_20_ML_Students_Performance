{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0f6f511",
   "metadata": {},
   "source": [
    "Inside - src/components/model_trainer.py\n",
    "\n",
    "Train and test datasets\n",
    "Convert datasets into X Features and y target column\n",
    "import the processor pickle file\n",
    "transform the X Features (don't process the target column)\n",
    "\n",
    "Train the model\n",
    "Give all the models\n",
    "give all the params for all the models\n",
    "train using grid search CV\n",
    "Get the best metric\n",
    "- Create the function required for model evaluation\n",
    "- Get all the metrics\n",
    "- Get all the params\n",
    "\n",
    "```Python\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79689e42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b247d7f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9cfa7d5",
   "metadata": {},
   "source": [
    "## Inside src/utils.py\n",
    "\n",
    "```python\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from src.exception import CustomException\n",
    "from src.logger import logging\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "## For RandomizedSearchCV\n",
    "#from sklearn.model_selection import RandomizedSearchCV\n",
    "#from scipy.stats import uniform\n",
    "\n",
    "\n",
    "def save_object(file_path, obj):\n",
    "    \"\"\"\n",
    "    Saves object. Saves pickle file object\n",
    "    from src.utils import save_object\n",
    "    save_object(file_path=, obj=)\n",
    "\n",
    "    Note: When using RandomizedSearchCV\n",
    "    Example of using it\n",
    "    from sklearn.model_selection import RandomizedSearchCV\n",
    "    from scipy.stats import uniform\n",
    "    param_dist = {\n",
    "    'C': uniform(0.1, 10),  # Uniform distribution between 0.1 and 10\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'gamma': ['scale', 'auto'] + list(np.logspace(-3, 3, 50))\n",
    "    }\n",
    "    # Create the RandomizedSearchCV object\n",
    "    randomized_search = RandomizedSearchCV(estimator=baseline_svm, param_distributions=param_dist, n_iter=20, cv=5)\n",
    "    \n",
    "    randomized_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Get the best hyperparameters and model\n",
    "    best_params_rand = randomized_search.best_params_\n",
    "    best_model_rand = randomized_search.best_estimator_\n",
    "    \n",
    "    # Evaluate the best model\n",
    "    y_pred_best_rand = best_model_rand.predict(X_test)\n",
    "    accuracy_best_rand = accuracy_score(y_test, y_pred_best_rand)\n",
    "    print(f\"Best SVM Accuracy: {accuracy_best_rand:.2f}\")\n",
    "    print(f\"Best Hyperparameters: {best_params_rand}\")\n",
    "    \"\"\"\n",
    "    try:\n",
    "        dir_path = os.path.dirname(file_path)\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "        \n",
    "        ## Error. It is not with os.open()\n",
    "        #with os.open(file_path, \"wb\") as file_obj:\n",
    "        with open(file_path, \"wb\") as file_obj:\n",
    "            pickle.dump(obj, file_obj)\n",
    "    except Exception as e:\n",
    "        raise CustomException(e,sys)\n",
    "    \n",
    "\n",
    "def load_object(file_path):\n",
    "    try:\n",
    "        #pass\n",
    "        with open(file_path, \"rb\") as file_obj:\n",
    "            return pickle.load(file_obj)\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise CustomException(e, sys)\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_models(X_train, y_train,X_test,y_test,models,param):\n",
    "    try:\n",
    "        report = {}\n",
    "\n",
    "        for i in range(len(list(models))):\n",
    "            model = list(models.values())[i]\n",
    "            para=param[list(models.keys())[i]]\n",
    "            \n",
    "            ## If Using RandomizedSearchCV\n",
    "            #rs = RandomizedSearchCV(model, param_distributions=para,cv=3)\n",
    "            #rs.fit(X_train, y_train)\n",
    "            #best_params_rand = model.set_params(**rs.best_params_)\n",
    "            ##best_model_rand = rs.best_estimator_\n",
    "\n",
    "            ## If using GridSearchCV\n",
    "            gs = GridSearchCV(model,para,cv=3)\n",
    "            gs.fit(X_train,y_train)\n",
    "\n",
    "            ## Unpack the dictionary\n",
    "            model.set_params(**gs.best_params_)\n",
    "            #model = model.set_params(**gs.best_params_)\n",
    "            model.fit(X_train,y_train)\n",
    "\n",
    "            #model.fit(X_train, y_train)  # Train model\n",
    "\n",
    "            y_train_pred = model.predict(X_train)\n",
    "\n",
    "            y_test_pred = model.predict(X_test)\n",
    "\n",
    "            train_model_score = r2_score(y_train, y_train_pred)\n",
    "\n",
    "            test_model_score = r2_score(y_test, y_test_pred)\n",
    "\n",
    "            report[list(models.keys())[i]] = test_model_score\n",
    "\n",
    "        return report\n",
    "\n",
    "    except Exception as e:\n",
    "        raise CustomException(e, sys)\n",
    "\n",
    "\n",
    "\n",
    "# def evaluate_models(X_train, y_train, X_test, y_test, models, param):\n",
    "#     \"\"\"\n",
    "#     Evaluates models, performs Grid Search, Selects the best parameters\n",
    "#     Selects the best models trains the model and performs metric evaluation\n",
    "#     from src.utils import evaluate_models\n",
    "#     evaluate_models(X_train=, y_train=, X_test=, y_test=, models=, param=)\n",
    "\n",
    "#     Args\n",
    "#       X_train\n",
    "#       y_train\n",
    "#       X_test\n",
    "#       y_test\n",
    "#       models\n",
    "#       param\n",
    "\n",
    "#       Calculates R2_Score\n",
    "\n",
    "#     Returns\n",
    "#       Report: dict Report\n",
    "    \n",
    "#       from src.utils import evaluate_models\n",
    "#       evaluate_models(X_train=, y_train=, X_test=, y_test=, models=, param=)\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         #pass\n",
    "#         report = {}\n",
    "\n",
    "#         for i in range(len(list(models))):\n",
    "#             model = list(models.values())[i]\n",
    "#             para=param[list(models.keys())[i]]\n",
    "\n",
    "#             gs = GridSearchCV(model, para, cv=3)\n",
    "#             gs.fit(X_train, y_train)\n",
    "#             #model.fit(X_train, y_train)\n",
    "            \n",
    "#             ## Getting best parameters and training the model with them\n",
    "#             model.set_params(**gs.best_params_)\n",
    "#             model.fit(X_train,y_train)\n",
    "\n",
    "#             y_train_pred = model.predict(X_train)\n",
    "#             y_test_pred = model.predict(X_test)\n",
    "\n",
    "#             train_model_score = r2_score(y_train, \n",
    "#                                          y_train_pred)\n",
    "            \n",
    "#             test_model_score = r2_score(y_test,\n",
    "#                                         y_test_pred)\n",
    "            \n",
    "#             report[list(models.keys())[i]] = test_model_score\n",
    "#         logging.info(f\"Returning Report from utils.evaluate_models function\")\n",
    "#         return report\n",
    "    \n",
    "#     except Exception as e:\n",
    "#         raise CustomException(e, sys)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6642c379",
   "metadata": {},
   "source": [
    "Inside model_trainer.py - src/components/model_trainer.py\n",
    "\n",
    "```python\n",
    "import os\n",
    "import sys\n",
    "from dataclasses import dataclass\n",
    "#import numpy as np\n",
    "#import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import (\n",
    "    AdaBoostRegressor,\n",
    "    GradientBoostingRegressor,\n",
    "    RandomForestRegressor\n",
    ")\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from src.exception import CustomException\n",
    "from src.logger import logging\n",
    "\n",
    "from src.utils import save_object, evaluate_models\n",
    "\n",
    "@dataclass\n",
    "class ModelTrainerConfig:\n",
    "    trained_model_file_path = os.path.join(\"artifacts\", \"model.pkl\")\n",
    "\n",
    "class ModelTrainer:\n",
    "    def __init__(self):\n",
    "        self.model_trainer_config = ModelTrainerConfig()\n",
    "    \n",
    "    def initiate_model_trainer(self, train_array, test_array):\n",
    "        try:\n",
    "            #pass\n",
    "            logging.info(\"Model Trainer Started\")\n",
    "            logging.info(\"Splitting the Train and Test Arrays\")\n",
    "            X_train,y_train,X_test,y_test=(\n",
    "                train_array[:,:-1],\n",
    "                train_array[:,-1],\n",
    "                test_array[:,:-1],\n",
    "                test_array[:,-1]\n",
    "            )\n",
    "            models = {\n",
    "                \"Random Forest\": RandomForestRegressor(),\n",
    "                \"Decision Tree\": DecisionTreeRegressor(),\n",
    "                \"Gradient Boosting\": GradientBoostingRegressor(),\n",
    "                \"Linear Regression\": LinearRegression(),\n",
    "                \"XGBRegressor\": XGBRegressor(),\n",
    "                \"CatBoosting Regressor\": CatBoostRegressor(verbose=False),\n",
    "                \"AdaBoost Regressor\": AdaBoostRegressor(),\n",
    "            }\n",
    "            params={\n",
    "                \"Decision Tree\": {\n",
    "                    'criterion':['squared_error', 'friedman_mse', 'absolute_error', 'poisson'],\n",
    "                    # 'splitter':['best','random'],\n",
    "                    # 'max_features':['sqrt','log2'],\n",
    "                },\n",
    "                \"Random Forest\":{\n",
    "                    # 'criterion':['squared_error', 'friedman_mse', 'absolute_error', 'poisson'],\n",
    "                 \n",
    "                    # 'max_features':['sqrt','log2',None],\n",
    "                    'n_estimators': [8,16,32,64,128,256]\n",
    "                },\n",
    "                \"Gradient Boosting\":{\n",
    "                    # 'loss':['squared_error', 'huber', 'absolute_error', 'quantile'],\n",
    "                    'learning_rate':[.1,.01,.05,.001],\n",
    "                    'subsample':[0.6,0.7,0.75,0.8,0.85,0.9],\n",
    "                    # 'criterion':['squared_error', 'friedman_mse'],\n",
    "                    # 'max_features':['auto','sqrt','log2'],\n",
    "                    'n_estimators': [8,16,32,64,128,256]\n",
    "                },\n",
    "                \"Linear Regression\":{},\n",
    "                \"XGBRegressor\":{\n",
    "                    'learning_rate':[.1,.01,.05,.001],\n",
    "                    'n_estimators': [8,16,32,64,128,256]\n",
    "                },\n",
    "                \"CatBoosting Regressor\":{\n",
    "                    'depth': [6,8,10],\n",
    "                    'learning_rate': [0.01, 0.05, 0.1],\n",
    "                    'iterations': [30, 50, 100]\n",
    "                },\n",
    "                \"AdaBoost Regressor\":{\n",
    "                    'learning_rate':[.1,.01,0.5,.001],\n",
    "                    # 'loss':['linear','square','exponential'],\n",
    "                    'n_estimators': [8,16,32,64,128,256]\n",
    "                }\n",
    "                \n",
    "            }\n",
    "\n",
    "            model_report:dict=evaluate_models(X_train=X_train,\n",
    "                                              y_train=y_train,\n",
    "                                              X_test=X_test,\n",
    "                                              y_test=y_test,\n",
    "                                              models=models,\n",
    "                                              param=params)\n",
    "            \n",
    "            ###Model Report Returns:\n",
    "            ###report[list(models.keys())[i]] = test_model_score\n",
    "\n",
    "            ## To get best model score from dict\n",
    "            best_model_score = max(sorted(model_report.values()))\n",
    "            #logging.info(\"Getting the best model score\")\n",
    "\n",
    "            ##To get the best model name from dict\n",
    "            ### model_report.keys()[getting index of best model score]\n",
    "            best_model_name = list(model_report.keys())[list(model_report.values()).index(best_model_score)]\n",
    "            ## Getting from all models the model name\n",
    "            best_model = models[best_model_name]\n",
    "            \n",
    "            print(f\"Best Model Score:\\n{best_model}\")\n",
    "            #print(\"Best Model Score:          \", end=\" \")\n",
    "            #print(best_model)\n",
    "\n",
    "            if best_model_score<0.6:\n",
    "                raise CustomException(\"Best Model Score is less than 0.6. Model is not good enough to be deployed.\")\n",
    "            \n",
    "            ## Dumping the model in a pickle file\n",
    "            save_object(\n",
    "                file_path=self.model_trainer_config.trained_model_file_path,\n",
    "                obj=best_model\n",
    "            )\n",
    "\n",
    "            ## Create prediction with best model and perform evaluation\n",
    "            predicted_test = best_model.predict(X_test)\n",
    "            r2_square_test = r2_score(y_true=y_test, y_pred=predicted_test)\n",
    "            \n",
    "            return r2_square_test\n",
    "        \n",
    "        except Exception as e:\n",
    "            raise CustomException(e,sys)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e79d9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_0760_20_01_ML_StudPerf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
